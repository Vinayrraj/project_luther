{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T17:29:21.755282Z",
     "start_time": "2018-10-02T17:29:18.261918Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import os\n",
    "import pprint\n",
    "import googlemaps\n",
    "import time\n",
    "import pickle\n",
    "from random import randint\n",
    "from collections import defaultdict\n",
    "import selenium\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline\n",
    "\n",
    "chromedriver = f\"/Users/brenner/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T17:43:04.630925Z",
     "start_time": "2018-10-02T17:43:04.625619Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use Seaborn whitegrid styling, because I like it\n",
    "import matplotlib.style as style\n",
    "style.use('seaborn-whitegrid')\n",
    "\n",
    "# Import private Google Maps API key\n",
    "MAPS_KEY = os.environ.get('MAPS_KEY')\n",
    "\n",
    "# Change format of charts to .svg\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T17:29:21.772486Z",
     "start_time": "2018-10-02T17:29:21.763290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Plain\n"
     ]
    }
   ],
   "source": [
    "%xmode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T17:41:25.426798Z",
     "start_time": "2018-10-02T17:41:25.242352Z"
    }
   },
   "outputs": [],
   "source": [
    "# This dataset contains house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.\n",
    "# Read the data into pandas dataframe\n",
    "df = pd.read_csv('kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T17:41:26.897346Z",
     "start_time": "2018-10-02T17:41:26.859902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view     ...      grade  sqft_above  \\\n",
       "0      5650     1.0           0     0     ...          7        1180   \n",
       "1      7242     2.0           0     0     ...          7        2170   \n",
       "2     10000     1.0           0     0     ...          6         770   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1955             0    98178  47.5112 -122.257   \n",
       "1            400      1951          1991    98125  47.7210 -122.319   \n",
       "2              0      1933             0    98028  47.7379 -122.233   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at the data\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recast price column as integer, for simplicity\n",
    "df['price'] = df.price.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = list(zip(df['lat'].astype(float), df['long'].astype(float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21613"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_addresses = []\n",
    "neighborhoods_list = []\n",
    "address_dictionary = defaultdict(str)\n",
    "\n",
    "def get_addresses(coords_list):\n",
    "    count = 0\n",
    "    for coord_tuple in coords_list:\n",
    "        count +=1\n",
    "#         if count >= 1000:\n",
    "#             time.sleep(120)\n",
    "#             count = 0\n",
    "        \n",
    "        try:\n",
    "            # Instantiate a Google Maps API session\n",
    "            address = gmaps.reverse_geocode(coord_tuple)\n",
    "            \n",
    "            # Parse the JSON results\n",
    "            formatted_address = address[1]['formatted_address']\n",
    "            \n",
    "            # Store both a list of formatted addresses and a list of all data for safekeeping\n",
    "            formatted_addresses.append(formatted_address)\n",
    "            \n",
    "            # Store a list of neighborhoods\n",
    "            neighborhood = address[0]['address_components'][2]['short_name']\n",
    "            neighborhoods_list.append(neighborhood)\n",
    "            \n",
    "            # Store a dictionary of lat/long and formatted addresses, in case we need to map to dataframe later\n",
    "            address_dictionary[coord_tuple] = formatted_address\n",
    "            \n",
    "            print('Success')\n",
    "\n",
    "        except:\n",
    "            print('Could not get address.')\n",
    "            formatted_addresses.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calls the Google API\n",
    "get_addresses(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21613"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(formatted_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pickling original list so not to lose my work\n",
    "# with open('address_list_final.pkl', 'wb') as f:\n",
    "#     pickle.dump(list_of_addresses, f)\n",
    "\n",
    "# with open('formatted_addresses.pkl', 'wb') as f:\n",
    "#     pickle.dump(formatted_addresses, f)\n",
    "\n",
    "# # Pickling like crazy because I don't want to lose my data.\n",
    "# # Yes, I know pickling isn't always the best. Works for now.\n",
    "# with open('json_addresses.pkl', 'wb') as f:\n",
    "#     pickle.dump(json_addresses, f)\n",
    "\n",
    "# with open('neighborhoods.pkl', 'wb') as f:\n",
    "#     pickle.dump(neighborhoods_list, f)\n",
    "\n",
    "# with open('address_dictionary.pkl', 'wb') as f:\n",
    "#     pickle.dump(address_dictionary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add formatted addresses from Google Maps API to our dataframe (!)\n",
    "df['Address'] = formatted_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding neighborhood to dataframe\n",
    "df['Neighborhood'] = neighborhoods_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start here once data is already scraped** <a name='bookmark' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the data is already scraped, we can pick up from here and add 'Address' column to main dataframe\n",
    "addresses_df = pd.read_csv('formatted_addresses_csv.csv')\n",
    "df['Address'] = addresses_df['Formatted Addresses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_df = pd.read_csv('Census Geocode Data/neighborhood_csv.csv', header=None)\n",
    "df['Neighborhood'] = neighborhood_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code in cell below is for imputing zip code from Google addresses, but we already have that data in another column. May return to this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Grab a list of all the zip codes from the formatted addresses list\n",
    "# # I love list comprehensions!\n",
    "# zip_list = [x.split(',')[-2][-5:] for x in formatted_addresses]\n",
    "\n",
    "# df['Imputed Zip Code'] = zip_list\n",
    "\n",
    "# def get_zips(x):\n",
    "#     if x == ' WA' or x == 'ngton':\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return x\n",
    "\n",
    "# df['Imputed Zip Code'] = df['Imputed Zip Code'].apply(get_zips)\n",
    "\n",
    "# df['Imputed Zip Code'] = df['Imputed Zip Code'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 205 Unique Neighborhoods. Should be sufficient for Walk Score/Transit Score/Bike Score etc. for our purposes.\n",
    "df['Neighborhood'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "adds = df['Address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "adds = adds.apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "adds = pd.DataFrame(adds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing from the address column to get individual street numbers, cities, etc. to feed into Census\n",
    "street_add = adds['Address'].apply(lambda x: x[0])\n",
    "\n",
    "city = adds['Address'].apply(lambda x: x[1])\n",
    "\n",
    "state = 'WA'\n",
    "\n",
    "zip = adds['Address'].apply(lambda x: x[2][4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WA    21613\n",
       "Name: Address, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a state column that doesn't have any wrong values\n",
    "state = adds['Address'].apply(lambda x: x[2][1:3])\n",
    "\n",
    "state = pd.DataFrame(state)\n",
    "\n",
    "state['Address'] = 'WA'\n",
    "\n",
    "state['Address'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.concat([street_add, city, state, zip], axis=1, names=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = output.iloc[8000:16000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>Address</th>\n",
       "      <th>Address</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8000</th>\n",
       "      <td>10261 39th Ave SW</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>98146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8001</th>\n",
       "      <td>17526 47th Ave NE</td>\n",
       "      <td>Lake Forest Park</td>\n",
       "      <td>WA</td>\n",
       "      <td>98155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8002</th>\n",
       "      <td>16116 NE 107th Ct</td>\n",
       "      <td>Redmond</td>\n",
       "      <td>WA</td>\n",
       "      <td>98052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8003</th>\n",
       "      <td>7024 126th Ave NE</td>\n",
       "      <td>Kirkland</td>\n",
       "      <td>WA</td>\n",
       "      <td>98033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8004</th>\n",
       "      <td>17242 164th Way SE</td>\n",
       "      <td>Renton</td>\n",
       "      <td>WA</td>\n",
       "      <td>98058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Address            Address Address Address\n",
       "8000   10261 39th Ave SW            Seattle      WA   98146\n",
       "8001   17526 47th Ave NE   Lake Forest Park      WA   98155\n",
       "8002   16116 NE 107th Ct            Redmond      WA   98052\n",
       "8003   7024 126th Ave NE           Kirkland      WA   98033\n",
       "8004  17242 164th Way SE             Renton      WA   98058"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bringing in all the Geocodes from the Census Data into one place, so we can add it to our df\n",
    "census_1 = pd.read_csv('Census Geocode Data/8000.csv', header=None)\n",
    "census_2 = pd.read_csv('Census Geocode Data/16000.csv', header=None)\n",
    "census_3 = pd.read_csv('Census Geocode Data/24000.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.concat([census_1, census_2, census_3], ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['index_num', 'Street', 'Match', 'Precision', 'Full address', 'loc', 'loc2', 'A', 'B', 'C', 'D', 'E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "census.sort_values('index_num', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walk Score Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_walk_scores(start, num_records_to_fetch):\n",
    "    '''Takes row number, number of rows to scrape data from, and returns Walk Score data.\n",
    "    Scrapes walkscore.com for Walk Score, Bike Score, Transit Score, Personal Crime Grade, and Property Crime Grade.\n",
    "    '''\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(start, start + num_records_to_fetch + 1):\n",
    "        address = df.iloc[i, df.columns.get_loc('Address')]\n",
    "        zipcode = df.iloc[i, df.columns.get_loc('zipcode')]\n",
    "        \n",
    "        if count==0:\n",
    "            # Fetch the URL\n",
    "            driver = webdriver.Chrome(chromedriver)\n",
    "            url_address = address.lower().replace(\",\", \"\").replace('.', '').replace(\" \", \"-\")\n",
    "            driver.get(f'https://www.walkscore.com/score/{url_address}')\n",
    "            time.sleep(5)\n",
    "    \n",
    "        \n",
    "        try:\n",
    "            # Take address from df, transform it and enter it into URL\n",
    "            url_address = address.lower().replace(\",\", \"\").replace('.', '').replace(\" \", \"-\")\n",
    "            driver.get(f'https://www.walkscore.com/score/{url_address}')\n",
    "#             time.sleep(1)\n",
    "            \n",
    "        except:\n",
    "            # Use the search bar if direct URL doesn't yield a page.\n",
    "            input_element = driver.find_element_by_id('addrbar-street')\n",
    "            input_element.clear()\n",
    "            input_element.click()\n",
    "            input_element.send_keys(address)\n",
    "            input_element.send_keys(Keys.ENTER)\n",
    "            \n",
    "            print('Search bar didn\\'t work.')\n",
    "        \n",
    "        # Read the html\n",
    "        html = driver.page_source\n",
    "        soup=BeautifulSoup(html)\n",
    "\n",
    "        # Getting Walk, Transit, and Bike Scores\n",
    "        image_tags = soup.find_all('img')\n",
    "        \n",
    "        try:\n",
    "            for score in image_tags:\n",
    "                if \"Score of\" in str(score):\n",
    "                    \n",
    "                    z = score['src']\n",
    "                    \n",
    "                    #Figure out which score (Walk/Transit/Bike) this is\n",
    "                    if 'walk/' in z:\n",
    "                        df.iloc[i, df.columns.get_loc('walk_score')] = z[-6:-4]\n",
    "                        print(f'Walk Score: {z[-6:-4]}')\n",
    "                    if 'transit/' in z:\n",
    "                        df.iloc[i, df.columns.get_loc('transit_score')] = z[-6:-4]\n",
    "                    if 'bike/' in z:\n",
    "                        df.iloc[i, df.columns.get_loc('bike_score')] = z[-6:-4]\n",
    "\n",
    "        except:\n",
    "            print(f'No Walk/Bike/Transit Score for {address}')\n",
    "\n",
    "        # Getting Personal & Property Crime Grades\n",
    "        results = soup.find_all(\"div\", {\"class\" : \"crime-grade\"})\n",
    "        parsed_grades = []\n",
    "            \n",
    "        try:\n",
    "            for grade in results:\n",
    "                parsed_grades.append(grade.text)\n",
    "\n",
    "            \n",
    "            df.iloc[i, df.columns.get_loc('pers_crime_score')] = parsed_grades[0][2]\n",
    "            df.iloc[i, df.columns.get_loc('prop_crime_score')] = parsed_grades[1][2]\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        print(f'{count} pages scraped. On index {i}.')\n",
    "        \n",
    "        count +=1\n",
    "        \n",
    "        # Backup data every 25 records\n",
    "        if count % 25 == 0:\n",
    "            df.to_csv('backup_df_from_scraping.csv')\n",
    "            print('Backed up dataframe.')\n",
    "            continue\n",
    "    \n",
    "        # Sleep for a bit if you've scraped 2000 records, and reinitialize     \n",
    "        if count % 2000 == 0:\n",
    "            time.sleep(randint(60, 600))\n",
    "            driver = webdriver.Chrome(chromedriver)\n",
    "            count = 0\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function call to scrape the data and pick up where you left off\n",
    "most_recent_record = df[df['walk_score'].isnull() == True].index[0]\n",
    "get_walk_scores(most_recent_record, 22000)\n",
    "# get_walk_scores(520,22000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    21588\n",
       "True        25\n",
       "Name: walk_score, dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['walk_score'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     13277\n",
       "False     8336\n",
       "Name: bike_score, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['bike_score'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding GEOID and income data to dataframe <a name='bookmark2' />**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NAs with float of 0.0 so we can run operations on the whole column to transform into full GEOID\n",
    "census['D'].fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add leading zeros to transform Census Tract ID into format we can use to find GEOID to match up with Census data\n",
    "def add_zeros(x):\n",
    "    x = str(int(x))\n",
    "    x = x.zfill(6)\n",
    "    return(x)\n",
    "\n",
    "census['tract'] = census['D'].apply(add_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the leading characters for GEOID to our tract number\n",
    "# Note: '53' denotes Washington State, and '033' denotes King County.\n",
    "census['GEOID'] = '53033' + census['tract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_num</th>\n",
       "      <th>Street</th>\n",
       "      <th>Match</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Full address</th>\n",
       "      <th>loc</th>\n",
       "      <th>loc2</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>tract</th>\n",
       "      <th>GEOID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>6101 S Cooper St,  Seattle, WA, 98118</td>\n",
       "      <td>Match</td>\n",
       "      <td>Non_Exact</td>\n",
       "      <td>6101 S COOPER ST, SEATTLE, WA, 98118</td>\n",
       "      <td>-122.25696,47.51166</td>\n",
       "      <td>239766052.0</td>\n",
       "      <td>R</td>\n",
       "      <td>53.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>011900</td>\n",
       "      <td>53033011900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>860 NE 127th St,  Seattle, WA, 98125</td>\n",
       "      <td>Match</td>\n",
       "      <td>Non_Exact</td>\n",
       "      <td>860 NE 127TH ST, SEATTLE, WA, 98125</td>\n",
       "      <td>-122.31958,47.721283</td>\n",
       "      <td>186716651.0</td>\n",
       "      <td>L</td>\n",
       "      <td>53.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>000200</td>\n",
       "      <td>53033000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2</td>\n",
       "      <td>15098 81st Ave NE,  Kenmore, WA, 98028</td>\n",
       "      <td>Match</td>\n",
       "      <td>Exact</td>\n",
       "      <td>15098 81ST AVE NE, KENMORE, WA, 98028</td>\n",
       "      <td>-122.23289,47.73783</td>\n",
       "      <td>239770253.0</td>\n",
       "      <td>R</td>\n",
       "      <td>53.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>22102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>022102</td>\n",
       "      <td>53033022102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>9247 Fauntleroy Way SW,  Seattle, WA, 98136</td>\n",
       "      <td>Match</td>\n",
       "      <td>Exact</td>\n",
       "      <td>9247 FAUNTLEROY WAY SW, SEATTLE, WA, 98136</td>\n",
       "      <td>-122.3935,47.520912</td>\n",
       "      <td>186661942.0</td>\n",
       "      <td>R</td>\n",
       "      <td>53.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>011600</td>\n",
       "      <td>53033011600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>4</td>\n",
       "      <td>757 222nd Pl NE,  Sammamish, WA, 98074</td>\n",
       "      <td>Match</td>\n",
       "      <td>Exact</td>\n",
       "      <td>757 222ND PL NE, SAMMAMISH, WA, 98074</td>\n",
       "      <td>-122.0446,47.61503</td>\n",
       "      <td>187001283.0</td>\n",
       "      <td>L</td>\n",
       "      <td>53.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>32317.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>032317</td>\n",
       "      <td>53033032317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index_num                                       Street  Match  Precision  \\\n",
       "55          0        6101 S Cooper St,  Seattle, WA, 98118  Match  Non_Exact   \n",
       "53          1         860 NE 127th St,  Seattle, WA, 98125  Match  Non_Exact   \n",
       "51          2       15098 81st Ave NE,  Kenmore, WA, 98028  Match      Exact   \n",
       "49          3  9247 Fauntleroy Way SW,  Seattle, WA, 98136  Match      Exact   \n",
       "73          4       757 222nd Pl NE,  Sammamish, WA, 98074  Match      Exact   \n",
       "\n",
       "                                  Full address                   loc  \\\n",
       "55        6101 S COOPER ST, SEATTLE, WA, 98118   -122.25696,47.51166   \n",
       "53         860 NE 127TH ST, SEATTLE, WA, 98125  -122.31958,47.721283   \n",
       "51       15098 81ST AVE NE, KENMORE, WA, 98028   -122.23289,47.73783   \n",
       "49  9247 FAUNTLEROY WAY SW, SEATTLE, WA, 98136   -122.3935,47.520912   \n",
       "73       757 222ND PL NE, SAMMAMISH, WA, 98074    -122.0446,47.61503   \n",
       "\n",
       "           loc2  A     B     C        D   E   tract        GEOID  \n",
       "55  239766052.0  R  53.0  33.0  11900.0 NaN  011900  53033011900  \n",
       "53  186716651.0  L  53.0  33.0    200.0 NaN  000200  53033000200  \n",
       "51  239770253.0  R  53.0  33.0  22102.0 NaN  022102  53033022102  \n",
       "49  186661942.0  R  53.0  33.0  11600.0 NaN  011600  53033011600  \n",
       "73  187001283.0  L  53.0  33.0  32317.0 NaN  032317  53033032317  "
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add 'GEOID' column to our main dataframe\n",
    "census.df['GEOID'] = census['GEOID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_income = pd.read_csv('Census Geocode Data/median_income.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the last entry because it contains a null value\n",
    "median_income = median_income.iloc[:-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEO.id2</th>\n",
       "      <th>HC02_EST_VC02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>53033005302</td>\n",
       "      <td>(X)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        GEO.id2 HC02_EST_VC02\n",
       "54  53033005302           (X)"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Found another incorrect value. Finding the index so I can drop it.\n",
    "median_income[median_income['HC02_EST_VC02'] == '(X)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GEO.id2          53033005302\n",
       "HC02_EST_VC02            (X)\n",
       "Name: 54, dtype: object"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_income.iloc[54]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping incorrect row.\n",
    "median_income = median_income.drop(54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index in order to make zipping into dicts possible without errors\n",
    "median_income = median_income.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recasting income variable as an int to make things easier down the road\n",
    "median_income['HC02_EST_VC02'] = median_income['HC02_EST_VC02'].astype('str', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary to map Census median HH income to df based on each house's GEOID\n",
    "income_tracts = dict(zip(median_income['GEO.id2'], median_income['HC02_EST_VC02']))\n",
    "\n",
    "# Do the mapping\n",
    "df['income'] = df['GEOID'].map(income_tracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96863"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity checking the GEOID of where I used to live - checks out\n",
    "income_tracts[53033022102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.to_csv('backups/backup_df_from_scraping.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Head over to 'Data Cleaning' notebook to pick up from here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
